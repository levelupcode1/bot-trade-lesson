#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìë™ë§¤ë§¤ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤ (ìµœì í™” ë²„ì „)
í†µí•©ëœ ìµœì í™”ëœ ë¶„ì„ íŒŒì´í”„ë¼ì¸
"""

import pandas as pd
import numpy as np
import time
import gc
import psutil
from typing import Dict, List, Optional, Any, Union
from datetime import datetime, timedelta
import logging
from dataclasses import dataclass, field
from pathlib import Path
import json
import threading
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

# ìµœì í™”ëœ ëª¨ë“ˆë“¤ import
from data_processor_optimized import OptimizedDataProcessor, DataConfig
from performance_metrics_optimized import OptimizedPerformanceAnalyzer, PerformanceMetrics
from visualization_optimized import OptimizedTradingVisualizer, ChartConfig
from statistical_analysis_optimized import OptimizedStatisticalAnalyzer, StatisticalResults
from error_handler_optimized import OptimizedErrorHandler, ErrorSeverity, ErrorCategory
from cache_batch_optimizer import OptimizedCacheBatchSystem, CacheConfig, BatchConfig

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class OptimizedAnalysisConfig:
    """ìµœì í™”ëœ ë¶„ì„ ì„¤ì • í´ë˜ìŠ¤"""
    # ë°ì´í„° ì„¤ì •
    data_config: DataConfig = field(default_factory=DataConfig)
    
    # ë¶„ì„ ì˜µì…˜
    enable_performance_analysis: bool = True
    enable_statistical_analysis: bool = True
    enable_visualization: bool = True
    enable_report_generation: bool = True
    
    # ìµœì í™” ì˜µì…˜
    enable_parallel_processing: bool = True
    enable_caching: bool = True
    enable_batch_processing: bool = True
    enable_error_recovery: bool = True
    
    # ì„±ëŠ¥ ì„¤ì •
    max_memory_usage_mb: int = 800
    max_processing_time_seconds: int = 300  # 5ë¶„
    chunk_size: int = 5000
    max_workers: int = None
    
    # ì¶œë ¥ ì„¤ì •
    report_formats: List[str] = field(default_factory=lambda: ["html", "json"])
    save_charts: bool = True
    chart_quality: str = "high"  # low, medium, high
    
    # ëª¨ë‹ˆí„°ë§ ì„¤ì •
    enable_performance_monitoring: bool = True
    enable_memory_monitoring: bool = True
    log_level: str = "INFO"
    
    def __post_init__(self):
        if self.max_workers is None:
            self.max_workers = min(mp.cpu_count(), 8)

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self, config: OptimizedAnalysisConfig):
        self.config = config
        self.start_time = None
        self.end_time = None
        self.phase_times = {}
        self.memory_usage = []
        self.process = psutil.Process()
        self.monitoring = False
        self.monitor_thread = None
    
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.start_time = time.time()
        self.monitoring = True
        
        if self.config.enable_memory_monitoring:
            self._start_memory_monitoring()
        
        logger.info("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.end_time = time.time()
        self.monitoring = False
        
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1.0)
        
        logger.info("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def _start_memory_monitoring(self):
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        def monitor_memory():
            while self.monitoring:
                try:
                    memory_mb = self.process.memory_info().rss / 1024 / 1024
                    self.memory_usage.append({
                        'timestamp': time.time(),
                        'memory_mb': memory_mb
                    })
                    
                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ë©´ ê²½ê³ 
                    if memory_mb > self.config.max_memory_usage_mb:
                        logger.warning(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì´ˆê³¼: {memory_mb:.1f}MB > {self.config.max_memory_usage_mb}MB")
                    
                    time.sleep(2.0)
                except Exception as e:
                    logger.error(f"ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                    time.sleep(2.0)
        
        self.monitor_thread = threading.Thread(target=monitor_memory, daemon=True)
        self.monitor_thread.start()
    
    def record_phase_time(self, phase: str, duration: float):
        """ë‹¨ê³„ë³„ ì‹œê°„ ê¸°ë¡"""
        self.phase_times[phase] = duration
        logger.debug(f"ë‹¨ê³„ '{phase}' ì™„ë£Œ: {duration:.3f}ì´ˆ")
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ë°˜í™˜"""
        total_time = self.end_time - self.start_time if self.end_time else 0
        
        peak_memory = max([m['memory_mb'] for m in self.memory_usage]) if self.memory_usage else 0
        avg_memory = np.mean([m['memory_mb'] for m in self.memory_usage]) if self.memory_usage else 0
        
        return {
            'total_time_seconds': total_time,
            'peak_memory_mb': peak_memory,
            'average_memory_mb': avg_memory,
            'phase_times': self.phase_times.copy(),
            'memory_samples': len(self.memory_usage),
            'efficiency_score': self._calculate_efficiency_score()
        }
    
    def _calculate_efficiency_score(self) -> float:
        """íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚° (0-100)"""
        if not self.phase_times:
            return 0.0
        
        total_time = sum(self.phase_times.values())
        if total_time == 0:
            return 100.0
        
        # ê° ë‹¨ê³„ë³„ ê°€ì¤‘ì¹˜
        weights = {
            'data_processing': 0.3,
            'performance_analysis': 0.25,
            'statistical_analysis': 0.2,
            'visualization': 0.15,
            'report_generation': 0.1
        }
        
        # ì˜ˆìƒ ì‹œê°„ ëŒ€ë¹„ ì‹¤ì œ ì‹œê°„ìœ¼ë¡œ íš¨ìœ¨ì„± ê³„ì‚°
        expected_ratios = {
            'data_processing': 0.3,
            'performance_analysis': 0.25,
            'statistical_analysis': 0.2,
            'visualization': 0.15,
            'report_generation': 0.1
        }
        
        efficiency_score = 100.0
        for phase, actual_time in self.phase_times.items():
            expected_ratio = expected_ratios.get(phase, 0.1)
            actual_ratio = actual_time / total_time
            ratio_diff = abs(actual_ratio - expected_ratio)
            efficiency_score -= ratio_diff * 200  # íŒ¨ë„í‹° ê³„ì‚°
        
        return max(0.0, min(100.0, efficiency_score))

class OptimizedTradingAnalyzer:
    """ìµœì í™”ëœ ìë™ë§¤ë§¤ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, config: OptimizedAnalysisConfig = None):
        self.config = config or OptimizedAnalysisConfig()
        self.logger = logging.getLogger(__name__)
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self._initialize_components()
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_monitor = PerformanceMonitor(self.config)
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.analysis_results = {}
        self.insights = []
        
        self.logger.info("ìµœì í™”ëœ ìë™ë§¤ë§¤ ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_components(self):
        """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            # ì˜¤ë¥˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ
            self.error_handler = OptimizedErrorHandler(
                log_file=f"logs/optimized_analysis_{datetime.now().strftime('%Y%m%d')}.log"
            )
            
            # ìºì‹± ë° ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ
            if self.config.enable_caching or self.config.enable_batch_processing:
                cache_config = CacheConfig(
                    max_memory_mb=self.config.max_memory_usage_mb // 2,
                    cache_dir="cache/optimized_analysis/"
                )
                batch_config = BatchConfig(
                    max_workers=self.config.max_workers,
                    memory_threshold_mb=self.config.max_memory_usage_mb
                )
                
                self.cache_batch_system = OptimizedCacheBatchSystem(cache_config, batch_config)
                self.cache_batch_system.start()
            else:
                self.cache_batch_system = None
            
            # ë°ì´í„° ì²˜ë¦¬ê¸°
            self.data_processor = OptimizedDataProcessor(self.config.data_config)
            
            # ì„±ê³¼ ë¶„ì„ê¸°
            if self.config.enable_performance_analysis:
                self.performance_analyzer = OptimizedPerformanceAnalyzer(
                    enable_parallel=self.config.enable_parallel_processing
                )
            
            # í†µê³„ ë¶„ì„ê¸°
            if self.config.enable_statistical_analysis:
                self.statistical_analyzer = OptimizedStatisticalAnalyzer(
                    enable_parallel=self.config.enable_parallel_processing
                )
            
            # ì‹œê°í™” ìƒì„±ê¸°
            if self.config.enable_visualization:
                chart_config = ChartConfig(
                    dpi=150 if self.config.chart_quality == "high" else 100,
                    save_path="optimized_charts/"
                )
                self.visualizer = OptimizedTradingVisualizer(chart_config)
            
            self.logger.info("ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            raise
    
    def run_comprehensive_analysis(self) -> Dict[str, Any]:
        """ìµœì í™”ëœ ì¢…í•© ë¶„ì„ ì‹¤í–‰"""
        start_time = time.time()
        
        try:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘
            if self.config.enable_performance_monitoring:
                self.performance_monitor.start_monitoring()
            
            self.logger.info("ìµœì í™”ëœ ì¢…í•© ë¶„ì„ ì‹œì‘")
            
            # 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
            processed_data = self._run_optimized_data_processing()
            if not processed_data:
                return {'error': 'ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨'}
            
            # 2ë‹¨ê³„: ì„±ê³¼ ë¶„ì„
            performance_results = self._run_optimized_performance_analysis(processed_data)
            
            # 3ë‹¨ê³„: í†µê³„ ë¶„ì„
            statistical_results = self._run_optimized_statistical_analysis(processed_data)
            
            # 4ë‹¨ê³„: ì‹œê°í™” ìƒì„±
            visualization_results = self._run_optimized_visualization(processed_data)
            
            # 5ë‹¨ê³„: ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
            insights = self._generate_optimized_insights(
                performance_results, statistical_results, processed_data
            )
            
            # 6ë‹¨ê³„: ë¦¬í¬íŠ¸ ìƒì„±
            report_results = self._generate_optimized_reports(
                performance_results, statistical_results, visualization_results, insights
            )
            
            # ê²°ê³¼ í†µí•©
            self.analysis_results = {
                'data_summary': self._get_data_summary(processed_data),
                'performance_analysis': performance_results,
                'statistical_analysis': statistical_results,
                'visualization_results': visualization_results,
                'insights': insights,
                'reports': report_results,
                'performance_metrics': self.performance_monitor.get_performance_summary(),
                'analysis_timestamp': datetime.now().isoformat()
            }
            
            total_time = time.time() - start_time
            self.logger.info(f"ìµœì í™”ëœ ì¢…í•© ë¶„ì„ ì™„ë£Œ: {total_time:.3f}ì´ˆ")
            
            return self.analysis_results
            
        except Exception as e:
            error_info = self.error_handler.handle_error(
                e,
                context={'analysis_type': 'comprehensive'},
                severity=ErrorSeverity.HIGH,
                category=ErrorCategory.SYSTEM
            )
            
            self.logger.error(f"ì¢…í•© ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'error': str(e), 'error_info': error_info}
        
        finally:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
            if self.config.enable_performance_monitoring:
                self.performance_monitor.stop_monitoring()
    
    def _run_optimized_data_processing(self) -> Optional[Dict[str, pd.DataFrame]]:
        """ìµœì í™”ëœ ë°ì´í„° ì²˜ë¦¬ ì‹¤í–‰"""
        phase_start = time.time()
        
        try:
            self.logger.info("1ë‹¨ê³„: ìµœì í™”ëœ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬")
            
            # ë°ì´í„° ë¡œë“œ (ìºì‹± í™œìš©)
            if self.cache_batch_system:
                @self.cache_batch_system.cached_function(ttl=1800)
                def load_data():
                    trades = self.data_processor.load_trade_data_optimized()
                    account = self.data_processor.load_account_history_optimized()
                    return trades, account
                
                trades, account = load_data()
            else:
                trades = self.data_processor.load_trade_data_optimized()
                account = self.data_processor.load_account_history_optimized()
            
            if trades.empty and account.empty:
                self.logger.warning("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ë°ì´í„° ì „ì²˜ë¦¬ (ë°°ì¹˜ ì²˜ë¦¬ í™œìš©)
            if self.cache_batch_system:
                @self.cache_batch_system.batch_processed_function()
                def preprocess_trades(trade_items):
                    return [self.data_processor.preprocess_trade_data_optimized(item) 
                           for item in trade_items]
                
                processed_trades = self.data_processor.preprocess_trade_data_optimized(trades)
            else:
                processed_trades = self.data_processor.preprocess_trade_data_optimized(trades)
            
            processed_account = self.data_processor.preprocess_account_data_optimized(account)
            
            phase_time = time.time() - phase_start
            self.performance_monitor.record_phase_time('data_processing', phase_time)
            
            self.logger.info(f"ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(processed_trades)}ê±´ ê±°ë˜, {len(processed_account)}ê±´ ê³„ì¢Œ")
            
            return {
                'trades': processed_trades,
                'account': processed_account
            }
            
        except Exception as e:
            self.error_handler.handle_error(
                e,
                context={'phase': 'data_processing'},
                severity=ErrorSeverity.HIGH,
                category=ErrorCategory.DATA
            )
            return None
    
    def _run_optimized_performance_analysis(self, processed_data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """ìµœì í™”ëœ ì„±ê³¼ ë¶„ì„ ì‹¤í–‰"""
        if not self.config.enable_performance_analysis:
            return {}
        
        phase_start = time.time()
        
        try:
            self.logger.info("2ë‹¨ê³„: ìµœì í™”ëœ ì„±ê³¼ ë¶„ì„")
            
            trades = processed_data['trades']
            account = processed_data['account']
            
            # ì¢…í•© ì„±ê³¼ ì§€í‘œ ê³„ì‚°
            overall_metrics = self.performance_analyzer.calculate_comprehensive_metrics(trades, account)
            
            # ì„¸ë¶„í™”ëœ ë¶„ì„
            symbol_analysis = {}
            strategy_analysis = {}
            
            if not trades.empty:
                # ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
                if self.config.enable_parallel_processing:
                    with ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
                        # ì½”ì¸ë³„ ë¶„ì„
                        symbols = trades['symbol'].unique()
                        symbol_futures = {
                            executor.submit(
                                self.performance_analyzer.analyze_by_symbol_optimized,
                                trades[trades['symbol'] == symbol], account
                            ): symbol for symbol in symbols
                        }
                        
                        for future in symbol_futures:
                            try:
                                symbol, metrics = future.result(timeout=30)
                                symbol_analysis[symbol] = metrics
                            except Exception as e:
                                logger.error(f"ì‹¬ë³¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
                        
                        # ì „ëµë³„ ë¶„ì„
                        strategies = trades['strategy'].unique()
                        strategy_futures = {
                            executor.submit(
                                self.performance_analyzer.analyze_by_strategy_optimized,
                                trades[trades['strategy'] == strategy], account
                            ): strategy for strategy in strategies
                        }
                        
                        for future in strategy_futures:
                            try:
                                strategy, metrics = future.result(timeout=30)
                                strategy_analysis[strategy] = metrics
                            except Exception as e:
                                logger.error(f"ì „ëµ ë¶„ì„ ì˜¤ë¥˜: {e}")
                else:
                    symbol_analysis = self.performance_analyzer.analyze_by_symbol_optimized(trades, account)
                    strategy_analysis = self.performance_analyzer.analyze_by_strategy_optimized(trades, account)
            
            phase_time = time.time() - phase_start
            self.performance_monitor.record_phase_time('performance_analysis', phase_time)
            
            self.logger.info("ì„±ê³¼ ë¶„ì„ ì™„ë£Œ")
            
            return {
                'overall_metrics': overall_metrics,
                'symbol_analysis': symbol_analysis,
                'strategy_analysis': strategy_analysis
            }
            
        except Exception as e:
            self.error_handler.handle_error(
                e,
                context={'phase': 'performance_analysis'},
                severity=ErrorSeverity.MEDIUM,
                category=ErrorCategory.CALCULATION
            )
            return {}
    
    def _run_optimized_statistical_analysis(self, processed_data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """ìµœì í™”ëœ í†µê³„ ë¶„ì„ ì‹¤í–‰"""
        if not self.config.enable_statistical_analysis:
            return {}
        
        phase_start = time.time()
        
        try:
            self.logger.info("3ë‹¨ê³„: ìµœì í™”ëœ í†µê³„ ë¶„ì„")
            
            trades = processed_data['trades']
            account = processed_data['account']
            
            # ì¢…í•© í†µê³„ ë¶„ì„
            statistical_results = self.statistical_analyzer.analyze_comprehensive_statistics(trades, account)
            
            phase_time = time.time() - phase_start
            self.performance_monitor.record_phase_time('statistical_analysis', phase_time)
            
            self.logger.info("í†µê³„ ë¶„ì„ ì™„ë£Œ")
            
            return statistical_results
            
        except Exception as e:
            self.error_handler.handle_error(
                e,
                context={'phase': 'statistical_analysis'},
                severity=ErrorSeverity.MEDIUM,
                category=ErrorCategory.CALCULATION
            )
            return {}
    
    def _run_optimized_visualization(self, processed_data: Dict[str, pd.DataFrame]) -> Dict[str, str]:
        """ìµœì í™”ëœ ì‹œê°í™” ì‹¤í–‰"""
        if not self.config.enable_visualization:
            return {}
        
        phase_start = time.time()
        
        try:
            self.logger.info("4ë‹¨ê³„: ìµœì í™”ëœ ì‹œê°í™” ìƒì„±")
            
            trades = processed_data['trades']
            account = processed_data['account']
            
            visualization_results = {}
            
            if not account.empty:
                # ìì‚° ê³¡ì„ 
                fig = self.visualizer.create_equity_curve_optimized(
                    account, save_file="optimized_equity_curve"
                )
                if fig:
                    visualization_results['equity_curve'] = "optimized_equity_curve"
                
                # ë‚™í­ ì°¨íŠ¸
                fig = self.visualizer.create_drawdown_chart_optimized(
                    account, save_file="optimized_drawdown"
                )
                if fig:
                    visualization_results['drawdown'] = "optimized_drawdown"
            
            if not trades.empty:
                # ê±°ë˜ ë¶„í¬
                fig = self.visualizer.create_trade_distribution_optimized(
                    trades, save_file="optimized_trade_distribution"
                )
                if fig:
                    visualization_results['trade_distribution'] = "optimized_trade_distribution"
            
            # ì¢…í•© ëŒ€ì‹œë³´ë“œ
            fig = self.visualizer.create_comprehensive_dashboard_optimized(
                trades, account, save_file="optimized_dashboard"
            )
            if fig:
                visualization_results['dashboard'] = "optimized_dashboard"
            
            phase_time = time.time() - phase_start
            self.performance_monitor.record_phase_time('visualization', phase_time)
            
            self.logger.info(f"ì‹œê°í™” ìƒì„± ì™„ë£Œ: {len(visualization_results)}ê°œ ì°¨íŠ¸")
            
            return visualization_results
            
        except Exception as e:
            self.error_handler.handle_error(
                e,
                context={'phase': 'visualization'},
                severity=ErrorSeverity.LOW,
                category=ErrorCategory.VISUALIZATION
            )
            return {}
    
    def _generate_optimized_insights(self, performance_results: Dict[str, Any], 
                                   statistical_results: Dict[str, Any],
                                   processed_data: Dict[str, pd.DataFrame]) -> List[Dict[str, Any]]:
        """ìµœì í™”ëœ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ"""
        insights = []
        
        try:
            # ì„±ê³¼ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            if 'overall_metrics' in performance_results:
                metrics = performance_results['overall_metrics']
                
                # ìˆ˜ìµë¥  ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
                if metrics.total_return < -10:
                    insights.append({
                        'type': 'warning',
                        'title': 'í° ì†ì‹¤ ë°œìƒ',
                        'description': f'ì´ ìˆ˜ìµë¥ ì´ {metrics.total_return:.2f}%ë¡œ í° ì†ì‹¤ì„ ë³´ì…ë‹ˆë‹¤.',
                        'recommendation': 'ì „ëµ ì¬ê²€í†  ë° ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê°•í™” í•„ìš”',
                        'priority': 'high'
                    })
                
                # ìŠ¹ë¥  ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
                if metrics.win_rate < 40:
                    insights.append({
                        'type': 'warning',
                        'title': 'ë‚®ì€ ìŠ¹ë¥ ',
                        'description': f'ìŠ¹ë¥ ì´ {metrics.win_rate:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤.',
                        'recommendation': 'ì§„ì…/ì²­ì‚° ì¡°ê±´ ì¬ê²€í†  í•„ìš”',
                        'priority': 'medium'
                    })
                
                # ìµœëŒ€ ë‚™í­ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
                if metrics.max_drawdown > 20:
                    insights.append({
                        'type': 'warning',
                        'title': 'ë†’ì€ ìµœëŒ€ ë‚™í­ ìœ„í—˜',
                        'description': f'ìµœëŒ€ ë‚™í­ì´ {metrics.max_drawdown:.2f}%ë¡œ ë¦¬ìŠ¤í¬ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.',
                        'recommendation': 'í¬ì§€ì…˜ í¬ê¸° ì¡°ì ˆ ë° ì†ì ˆë§¤ ê°•í™”',
                        'priority': 'high'
                    })
            
            # í†µê³„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            if 'DAILY_RETURNS' in statistical_results:
                daily_returns_stats = statistical_results['DAILY_RETURNS']
                
                if daily_returns_stats.skewness < -0.5:
                    insights.append({
                        'type': 'info',
                        'title': 'ìŒì˜ ì™œë„ ê°ì§€',
                        'description': f'ì¼ì¼ ìˆ˜ìµë¥ ì˜ ì™œë„ê°€ {daily_returns_stats.skewness:.3f}ë¡œ ìŒì˜ ê°’ì…ë‹ˆë‹¤.',
                        'recommendation': 'í° ì†ì‹¤ ê°€ëŠ¥ì„±ì— ëŒ€í•œ ëŒ€ë¹„ì±… í•„ìš”',
                        'priority': 'medium'
                    })
            
            # ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            if not processed_data['trades'].empty:
                trades = processed_data['trades']
                
                # ì‹œê°„ëŒ€ë³„ ê±°ë˜ ë¶„ì„
                trades['hour'] = trades['created_at'].dt.hour
                hourly_volume = trades.groupby('hour').size()
                
                if len(hourly_volume) > 0:
                    peak_hour = hourly_volume.idxmax()
                    insights.append({
                        'type': 'info',
                        'title': 'ìµœì  ê±°ë˜ ì‹œê°„ëŒ€',
                        'description': f'{peak_hour}ì‹œì— ê°€ì¥ ë§ì€ ê±°ë˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
                        'recommendation': 'í•´ë‹¹ ì‹œê°„ëŒ€ì˜ ì‹œì¥ íŠ¹ì„± ë¶„ì„ ê¶Œì¥',
                        'priority': 'low'
                    })
            
            self.logger.info(f"{len(insights)}ê°œì˜ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ")
            
        except Exception as e:
            self.error_handler.handle_error(
                e,
                context={'phase': 'insights_generation'},
                severity=ErrorSeverity.LOW,
                category=ErrorCategory.CALCULATION
            )
        
        return insights
    
    def _generate_optimized_reports(self, performance_results: Dict[str, Any],
                                  statistical_results: Dict[str, Any],
                                  visualization_results: Dict[str, str],
                                  insights: List[Dict[str, Any]]) -> Dict[str, str]:
        """ìµœì í™”ëœ ë¦¬í¬íŠ¸ ìƒì„±"""
        phase_start = time.time()
        
        try:
            self.logger.info("6ë‹¨ê³„: ìµœì í™”ëœ ë¦¬í¬íŠ¸ ìƒì„±")
            
            reports = {}
            
            # JSON ë¦¬í¬íŠ¸
            if "json" in self.config.report_formats:
                json_report = {
                    'analysis_timestamp': datetime.now().isoformat(),
                    'performance_results': performance_results,
                    'statistical_results': statistical_results,
                    'visualization_files': visualization_results,
                    'insights': insights,
                    'performance_metrics': self.performance_monitor.get_performance_summary()
                }
                
                json_file = f"optimized_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump(json_report, f, indent=2, ensure_ascii=False, default=str)
                
                reports['json'] = json_file
            
            # HTML ë¦¬í¬íŠ¸ (ê°„ë‹¨í•œ ë²„ì „)
            if "html" in self.config.report_formats:
                html_content = self._generate_html_report(
                    performance_results, statistical_results, insights
                )
                
                html_file = f"optimized_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
                with open(html_file, 'w', encoding='utf-8') as f:
                    f.write(html_content)
                
                reports['html'] = html_file
            
            phase_time = time.time() - phase_start
            self.performance_monitor.record_phase_time('report_generation', phase_time)
            
            self.logger.info(f"ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {list(reports.keys())}")
            
            return reports
            
        except Exception as e:
            self.error_handler.handle_error(
                e,
                context={'phase': 'report_generation'},
                severity=ErrorSeverity.LOW,
                category=ErrorCategory.SYSTEM
            )
            return {}
    
    def _generate_html_report(self, performance_results: Dict[str, Any],
                            statistical_results: Dict[str, Any],
                            insights: List[Dict[str, Any]]) -> str:
        """HTML ë¦¬í¬íŠ¸ ìƒì„±"""
        html_template = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ìµœì í™”ëœ ìë™ë§¤ë§¤ ë¶„ì„ ë¦¬í¬íŠ¸</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background-color: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}
        h2 {{ color: #34495e; margin-top: 30px; }}
        .metric-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 15px; margin: 20px 0; }}
        .metric-card {{ background-color: #ecf0f1; padding: 15px; border-radius: 5px; border-left: 4px solid #3498db; }}
        .metric-value {{ font-size: 24px; font-weight: bold; color: #2c3e50; }}
        .metric-label {{ font-size: 14px; color: #7f8c8d; }}
        .insight {{ margin: 10px 0; padding: 15px; border-radius: 5px; }}
        .insight.warning {{ background-color: #fdf2e9; border-left: 4px solid #e67e22; }}
        .insight.info {{ background-color: #e8f4fd; border-left: 4px solid #3498db; }}
        .performance-summary {{ background-color: #f8f9fa; padding: 20px; border-radius: 5px; margin: 20px 0; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
        th {{ background-color: #f2f2f2; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸš€ ìµœì í™”ëœ ìë™ë§¤ë§¤ ë¶„ì„ ë¦¬í¬íŠ¸</h1>
        <p><strong>ìƒì„± ì‹œê°„:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        
        <h2>ğŸ“Š ì„±ê³¼ ìš”ì•½</h2>
        <div class="performance-summary">
"""
        
        # ì„±ê³¼ ì§€í‘œ ì¶”ê°€
        if 'overall_metrics' in performance_results:
            metrics = performance_results['overall_metrics']
            html_template += f"""
            <div class="metric-grid">
                <div class="metric-card">
                    <div class="metric-value">{metrics.total_return:.2f}%</div>
                    <div class="metric-label">ì´ ìˆ˜ìµë¥ </div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{metrics.win_rate:.1f}%</div>
                    <div class="metric-label">ìŠ¹ë¥ </div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{metrics.max_drawdown:.2f}%</div>
                    <div class="metric-label">ìµœëŒ€ ë‚™í­</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{metrics.sharpe_ratio:.2f}</div>
                    <div class="metric-label">ìƒ¤í”„ ë¹„ìœ¨</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{metrics.total_trades}</div>
                    <div class="metric-label">ì´ ê±°ë˜ ìˆ˜</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{metrics.avg_holding_period:.0f}ë¶„</div>
                    <div class="metric-label">í‰ê·  ë³´ìœ  ê¸°ê°„</div>
                </div>
            </div>
"""
        
        html_template += """
        </div>
        
        <h2>ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸</h2>
"""
        
        # ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
        for insight in insights:
            priority_class = insight.get('priority', 'info')
            html_template += f"""
        <div class="insight {priority_class}">
            <h3>{insight.get('title', 'ì¸ì‚¬ì´íŠ¸')}</h3>
            <p><strong>ì„¤ëª…:</strong> {insight.get('description', '')}</p>
            <p><strong>ê¶Œì¥ì‚¬í•­:</strong> {insight.get('recommendation', '')}</p>
            <p><strong>ìš°ì„ ìˆœìœ„:</strong> {insight.get('priority', 'low')}</p>
        </div>
"""
        
        # ì„±ëŠ¥ ì •ë³´ ì¶”ê°€
        performance_metrics = self.performance_monitor.get_performance_summary()
        html_template += f"""
        <h2>âš¡ ì„±ëŠ¥ ì •ë³´</h2>
        <div class="performance-summary">
            <p><strong>ì´ ë¶„ì„ ì‹œê°„:</strong> {performance_metrics['total_time_seconds']:.3f}ì´ˆ</p>
            <p><strong>ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:</strong> {performance_metrics['peak_memory_mb']:.1f}MB</p>
            <p><strong>íš¨ìœ¨ì„± ì ìˆ˜:</strong> {performance_metrics['efficiency_score']:.1f}/100</p>
        </div>
        
        <h2>ğŸ“ˆ ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„</h2>
        <table>
            <tr><th>ë‹¨ê³„</th><th>ì²˜ë¦¬ ì‹œê°„</th></tr>
"""
        
        for phase, duration in performance_metrics['phase_times'].items():
            html_template += f"<tr><td>{phase}</td><td>{duration:.3f}ì´ˆ</td></tr>"
        
        html_template += """
        </table>
        
        <footer style="margin-top: 40px; padding-top: 20px; border-top: 1px solid #ddd; color: #7f8c8d; text-align: center;">
            <p>ìµœì í™”ëœ ìë™ë§¤ë§¤ ë¶„ì„ ì‹œìŠ¤í…œ v2.0</p>
        </footer>
    </div>
</body>
</html>
"""
        
        return html_template
    
    def _get_data_summary(self, processed_data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """ë°ì´í„° ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        trades = processed_data.get('trades', pd.DataFrame())
        account = processed_data.get('account', pd.DataFrame())
        
        summary = {
            'trades_count': len(trades),
            'account_records': len(account),
            'date_range': {
                'start': trades['created_at'].min().isoformat() if not trades.empty else None,
                'end': trades['created_at'].max().isoformat() if not trades.empty else None
            },
            'symbols': trades['symbol'].unique().tolist() if not trades.empty else [],
            'strategies': trades['strategy'].unique().tolist() if not trades.empty else []
        }
        
        return summary
    
    def get_analysis_summary(self) -> str:
        """ë¶„ì„ ìš”ì•½ ë°˜í™˜"""
        if not self.analysis_results:
            return "ë¶„ì„ì´ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        summary = f"""
=== ìµœì í™”ëœ ìë™ë§¤ë§¤ ë¶„ì„ ìš”ì•½ ===
ë¶„ì„ ì‹œê°„: {self.analysis_results.get('analysis_timestamp', 'N/A')}

ğŸ“Š í•µì‹¬ ì§€í‘œ
"""
        
        if 'performance_analysis' in self.analysis_results:
            perf_results = self.analysis_results['performance_analysis']
            if 'overall_metrics' in perf_results:
                metrics = perf_results['overall_metrics']
                summary += f"- ì´ ìˆ˜ìµë¥ : {metrics.total_return:.2f}%\n"
                summary += f"- ìŠ¹ë¥ : {metrics.win_rate:.1f}%\n"
                summary += f"- ìµœëŒ€ ë‚™í­: {metrics.max_drawdown:.2f}%\n"
                summary += f"- ìƒ¤í”„ ë¹„ìœ¨: {metrics.sharpe_ratio:.2f}\n"
                summary += f"- ì´ ê±°ë˜ ìˆ˜: {metrics.total_trades}ê±´\n"
        
        summary += f"\nğŸ“ˆ ìƒì„±ëœ ì°¨íŠ¸: {len(self.analysis_results.get('visualization_results', {}))}ê°œ\n"
        summary += f"ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸: {len(self.analysis_results.get('insights', []))}ê°œ\n"
        
        if 'reports' in self.analysis_results:
            reports = self.analysis_results['reports']
            summary += f"\nğŸ“„ ìƒì„±ëœ ë¦¬í¬íŠ¸:\n"
            for format_type, filename in reports.items():
                summary += f"- {format_type.upper()}: {filename}\n"
        
        return summary
    
    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.cache_batch_system:
                self.cache_batch_system.cleanup_resources()
            
            if hasattr(self, 'visualizer'):
                self.visualizer.cleanup_resources()
            
            self.error_handler.cleanup_resources()
            
            gc.collect()
            
            self.logger.info("ìµœì í™”ëœ ë¶„ì„ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì˜¤ë¥˜: {e}")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    import time
    
    # ìµœì í™”ëœ ì„¤ì •
    data_config = DataConfig(
        db_path="data/optimized_trading.db",
        data_period_days=90,
        chunk_size=5000
    )
    
    analysis_config = OptimizedAnalysisConfig(
        data_config=data_config,
        enable_performance_analysis=True,
        enable_statistical_analysis=True,
        enable_visualization=True,
        enable_report_generation=True,
        enable_parallel_processing=True,
        enable_caching=True,
        enable_batch_processing=True,
        max_memory_usage_mb=600,
        max_processing_time_seconds=300,
        report_formats=["html", "json"],
        chart_quality="high"
    )
    
    # ìµœì í™”ëœ ë¶„ì„ê¸° ìƒì„±
    analyzer = OptimizedTradingAnalyzer(analysis_config)
    
    try:
        # ì¢…í•© ë¶„ì„ ì‹¤í–‰
        start_time = time.time()
        results = analyzer.run_comprehensive_analysis()
        total_time = time.time() - start_time
        
        # ê²°ê³¼ ì¶œë ¥
        print("=== ìµœì í™”ëœ ìë™ë§¤ë§¤ ë¶„ì„ ê²°ê³¼ ===")
        print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.3f}ì´ˆ")
        
        if 'error' not in results:
            summary = analyzer.get_analysis_summary()
            print(summary)
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶œë ¥
            if 'performance_metrics' in results:
                perf_metrics = results['performance_metrics']
                print(f"\n=== ì„±ëŠ¥ ì •ë³´ ===")
                print(f"íš¨ìœ¨ì„± ì ìˆ˜: {perf_metrics['efficiency_score']:.1f}/100")
                print(f"ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {perf_metrics['peak_memory_mb']:.1f}MB")
                print(f"ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„:")
                for phase, duration in perf_metrics['phase_times'].items():
                    print(f"  - {phase}: {duration:.3f}ì´ˆ")
        else:
            print(f"ë¶„ì„ ì˜¤ë¥˜: {results['error']}")
    
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        analyzer.cleanup_resources()
        print("ë¶„ì„ ì™„ë£Œ!")









